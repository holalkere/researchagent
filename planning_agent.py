# -*- coding: utf-8 -*-
import json
import re
from typing import List
from datetime import datetime
from aisuite import Client
from src.agents import (
    research_agent,
    writer_agent,
    editor_agent,
)

client = Client()


def clean_json_block(raw: str) -> str:
    raw = raw.strip()
    if raw.startswith("```"):
        raw = re.sub(r"^```[a-zA-Z]*\n?", "", raw)
        raw = re.sub(r"\n?```$", "", raw)
    return raw.strip("` \n")


from typing import List
import json, ast


def planner_agent(topic: str, model: str = "openai:o4-mini") -> List[str]:
    # Use direct API keys instead of environment variables
    import os
    
    # Set API keys directly in the environment for this session
    # API keys are loaded from .env file via load_dotenv() in main.py
    
    api_key = os.getenv("OPENAI_API_KEY", "")
    if not api_key or api_key.startswith("sk-test-") or api_key == "sk-proj-your-openai-api-key-here":
        print("Test mode: Using mock planning steps")
        return [
            "Research agent: Use Tavily to perform a broad web search and collect top relevant items (title, authors, year, venue/source, URL, DOI if available).",
            "Research agent: For each collected item, search on arXiv to find matching preprints/versions and record arXiv URLs (if they exist).",
            "Research agent: Synthesize and rank findings by relevance, recency, and authority; deduplicate by title/DOI.",
            "Writer agent: Draft a structured outline based on the ranked evidence.",
            "Editor agent: Review for coherence, coverage, and citation completeness; request fixes.",
            "Writer agent: Generate the final comprehensive Markdown report with inline citations and a complete References section with clickable links."
        ]
    
    prompt = f"""
You are a planning agent responsible for organizing a research workflow using multiple intelligent agents.

Available agents:
- Research agent: MUST begin with a broad **web search using Tavily** to identify only **relevant** and **authoritative** items (e.g., high-impact venues, seminal works, surveys, or recent comprehensive sources). The output of this step MUST capture for each candidate: title, authors, year, venue/source, URL, and (if available) DOI.
- Research agent: AFTER the Tavily step, perform a **targeted arXiv search** ONLY for the candidates discovered in the web step (match by title/author/DOI). If an arXiv preprint/version exists, record its arXiv URL and version info. Do NOT run a generic arXiv search detached from the Tavily results.
- Writer agent: drafts based on research findings.
- Editor agent: reviews, reflects on, and improves drafts.

Produce a clear step-by-step research plan **as a valid Python list of strings** (no markdown, no explanations). 
Each step must be atomic, actionable, and assigned to one of the agents.
Maximum of 7 steps.

DO NOT include steps like "create CSV", "set up repo", "install packages".
Focus on meaningful research tasks (search, extract, rank, draft, revise).
The FIRST step MUST be exactly: 
"Research agent: Use Tavily to perform a broad web search and collect top relevant items (title, authors, year, venue/source, URL, DOI if available)."
The SECOND step MUST be exactly:
"Research agent: For each collected item, search on arXiv to find matching preprints/versions and record arXiv URLs (if they exist)."

The FINAL step MUST instruct the writer agent to generate a comprehensive Markdown report that:
- Uses all findings and outputs from previous steps
- Includes inline citations (e.g., [1], (Wikipedia/arXiv))
- Includes a References section with clickable links for all citations
- Preserves earlier sources
- Is detailed and self-contained

Topic: "{topic}"
"""

    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}],
        temperature=1,
    )

    raw = response.choices[0].message.content.strip()

    # --- robust parsing: JSON -> ast -> fallback ---
    def _coerce_to_list(s: str) -> List[str]:
        # try strict JSON
        try:
            obj = json.loads(s)
            if isinstance(obj, list) and all(isinstance(x, str) for x in obj):
                return obj[:7]
        except json.JSONDecodeError:
            pass
        # try Python literal list
        try:
            obj = ast.literal_eval(s)
            if isinstance(obj, list) and all(isinstance(x, str) for x in obj):
                return obj[:7]
        except Exception:
            pass
        # try to extract code fence if present
        if s.startswith("```") and s.endswith("```"):
            inner = s.strip("`")
            try:
                obj = ast.literal_eval(inner)
                if isinstance(obj, list) and all(isinstance(x, str) for x in obj):
                    return obj[:7]
            except Exception:
                pass
        return []

    steps = _coerce_to_list(raw)

    # enforce ordering & minimal contract
    required_first = "Research agent: Use Tavily to perform a broad web search and collect top relevant items (title, authors, year, venue/source, URL, DOI if available)."
    required_second = "Research agent: For each collected item, search on arXiv to find matching preprints/versions and record arXiv URLs (if they exist)."
    final_required = "Writer agent: Generate the final comprehensive Markdown report with inline citations and a complete References section with clickable links."

    def _ensure_contract(steps_list: List[str]) -> List[str]:
        if not steps_list:
            return [
                required_first,
                required_second,
                "Research agent: Synthesize and rank findings by relevance, recency, and authority; deduplicate by title/DOI.",
                "Writer agent: Draft a structured outline based on the ranked evidence.",
                "Editor agent: Review for coherence, coverage, and citation completeness; request fixes.",
                final_required,
            ]
        # inject/replace first two if missing or out of order
        steps_list = [s for s in steps_list if isinstance(s, str)]
        if not steps_list or steps_list[0] != required_first:
            steps_list = [required_first] + steps_list
        if len(steps_list) < 2 or steps_list[1] != required_second:
            # remove any generic arxiv step that is not tied to Tavily results
            steps_list = (
                [steps_list[0]]
                + [required_second]
                + [
                    s
                    for s in steps_list[1:]
                    if "arXiv" not in s or "For each collected item" in s
                ]
            )
        # ensure final step requirement present
        if final_required not in steps_list:
            steps_list.append(final_required)
        # cap to 7
        return steps_list[:7]

    steps = _ensure_contract(steps)

    return steps


def executor_agent_step(step_title: str, history: list, prompt: str):
    """
    Executes a step of the executor agent.
    Returns:
        - step_title (str)
        - agent_name (str)
        - output (str)
    """
    
    # Test mode - return mock data if API key is invalid
    import os
    api_key = os.getenv("OPENAI_API_KEY", "")
    if not api_key or api_key.startswith("sk-test-"):
        print(f"Test mode: Mock execution for step: {step_title}")
        step_lower = step_title.lower()
        if "research" in step_lower:
            mock_output = f"""# Research Results for: {prompt}

## Web Search Results (Tavily)
1. **"Recent Advances in Large Language Models for Scientific Research"** - Nature Machine Intelligence, 2024
   - Authors: Smith, J., et al.
   - URL: https://example.com/paper1
   - DOI: 10.1038/s42256-024-00001

2. **"Transformer Architectures in Drug Discovery"** - Science, 2024
   - Authors: Johnson, A., et al.
   - URL: https://example.com/paper2
   - DOI: 10.1126/science.abc123

## arXiv Search Results
- Found matching preprint: "Large Language Models for Scientific Discovery" (arXiv:2401.12345)
- Found matching preprint: "Transformer-based Drug Discovery" (arXiv:2402.67890)

## Summary
This research identified key papers on LLM applications in scientific research, focusing on transformer architectures and drug discovery applications."""
            return step_title, "research_agent", mock_output
        elif "draft" in step_lower or "write" in step_lower:
            mock_output = f"""# {prompt}

## Abstract
This report examines recent developments in large language models for scientific research, focusing on transformer architectures, drug discovery applications, and performance benchmarks.

## Introduction
Large language models have revolutionized scientific research by enabling automated analysis and discovery processes.

## Key Findings
1. Transformer architectures show significant promise in scientific applications
2. Drug discovery applications demonstrate practical utility
3. Performance benchmarks indicate substantial improvements over traditional methods

## References
[1] Smith, J., et al. (2024). Recent Advances in Large Language Models for Scientific Research. Nature Machine Intelligence.
[2] Johnson, A., et al. (2024). Transformer Architectures in Drug Discovery. Science."""
            return step_title, "writer_agent", mock_output
        elif "revise" in step_lower or "edit" in step_lower or "feedback" in step_lower:
            mock_output = f"""# Enhanced Report: {prompt}

## Abstract
This comprehensive report examines recent developments in large language models for scientific research, with particular focus on transformer architectures, drug discovery applications, and performance benchmarks. The analysis reveals significant advances in automated scientific discovery processes.

## Introduction
Large language models have emerged as transformative tools in scientific research, enabling unprecedented capabilities in automated analysis, hypothesis generation, and discovery processes. This report synthesizes recent developments across multiple domains.

## Key Findings
1. **Transformer Architectures**: Show exceptional promise in scientific applications with improved attention mechanisms
2. **Drug Discovery Applications**: Demonstrate practical utility in molecular design and drug-target interaction prediction
3. **Performance Benchmarks**: Indicate substantial improvements over traditional computational methods

## Discussion
The integration of LLMs into scientific workflows represents a paradigm shift in research methodology.

## References
[1] Smith, J., et al. (2024). Recent Advances in Large Language Models for Scientific Research. Nature Machine Intelligence. https://example.com/paper1
[2] Johnson, A., et al. (2024). Transformer Architectures in Drug Discovery. Science. https://example.com/paper2"""
            return step_title, "editor_agent", mock_output
        else:
            mock_output = f"Mock output for step: {step_title}"
            return step_title, "mock_agent", mock_output

    # Construir contexto enriquecido estructurado
    context = f"User Prompt:\n{prompt}\n\nHistory so far:\n"
    for i, (desc, agent, output) in enumerate(history):
        if "draft" in desc.lower() or agent == "writer_agent":
            context += f"\nDraft (Step {i + 1}):\n{output.strip()}\n"
        elif "feedback" in desc.lower() or agent == "editor_agent":
            context += f"\nFeedback (Step {i + 1}):\n{output.strip()}\n"
        elif "research" in desc.lower() or agent == "research_agent":
            context += f"\nResearch (Step {i + 1}):\n{output.strip()}\n"
        else:
            context += f"\nOther (Step {i + 1}) by {agent}:\n{output.strip()}\n"

    enriched_task = f"""{context}

Your next task:
{step_title}
"""

    # Seleccionar agente basado en el paso
    step_lower = step_title.lower()
    if "research" in step_lower:
        content, _ = research_agent(prompt=enriched_task)
        print("Research Agent Output:", content)
        return step_title, "research_agent", content
    elif "draft" in step_lower or "write" in step_lower:
        content, _ = writer_agent(prompt=enriched_task)
        return step_title, "writer_agent", content
    elif "revise" in step_lower or "edit" in step_lower or "feedback" in step_lower:
        content, _ = editor_agent(prompt=enriched_task)
        return step_title, "editor_agent", content
    else:
        raise ValueError(f"Unknown step type: {step_title}")
